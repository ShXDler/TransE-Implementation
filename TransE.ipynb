{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d78cb076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5b05b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Knowledge Graph...\n",
      "Finish loading entity:43234, relation:18, train triples:133582, valid triples:4053, test triples:4054\n"
     ]
    }
   ],
   "source": [
    "KG_path = 'TransE/kg/MetaQA/'\n",
    "print('Load Knowledge Graph...')\n",
    "with open(KG_path + 'entities.dict') as file_e:\n",
    "    lines = file_e.readlines()\n",
    "    entity_dict = {}\n",
    "    entityind_dict = {}\n",
    "    for line in lines:\n",
    "        ent, ind = line.strip().split('\\t')\n",
    "        entity_dict[ent] = int(ind)\n",
    "        entityind_dict[int(ind)] = ent\n",
    "\n",
    "with open(KG_path + 'relations.dict') as file_r:\n",
    "    lines = file_r.readlines()\n",
    "    relation_dict = {}\n",
    "    relationind_dict = {}\n",
    "    for line in lines:\n",
    "        rel, ind = line.strip().split('\\t')\n",
    "        relation_dict[rel] = int(ind)\n",
    "        relationind_dict[int(ind)] = rel\n",
    "        \n",
    "with open(KG_path + 'train.txt') as file_train:\n",
    "    lines = file_train.readlines()\n",
    "    train_triple_list = []\n",
    "    for line in lines:\n",
    "        h, r, t = line.strip().split('\\t')\n",
    "        train_triple_list.append([entity_dict[h], relation_dict[r], entity_dict[t]])\n",
    "\n",
    "with open(KG_path + 'valid.txt') as file_valid:\n",
    "    lines = file_valid.readlines()\n",
    "    valid_triple_list = []\n",
    "    for line in lines:\n",
    "        h, r, t = line.strip().split('\\t')\n",
    "        valid_triple_list.append([entity_dict[h], relation_dict[r], entity_dict[t]])\n",
    "        \n",
    "with open(KG_path + 'test.txt') as file_valid:\n",
    "    lines = file_valid.readlines()\n",
    "    test_triple_list = []\n",
    "    for line in lines:\n",
    "        h, r, t = line.strip().split('\\t')\n",
    "        test_triple_list.append([entity_dict[h], relation_dict[r], entity_dict[t]])\n",
    "print(f'Finish loading entity:{len(entity_dict)}, relation:{len(relation_dict)}, \\\n",
    "train triples:{len(train_triple_list)}, valid triples:{len(valid_triple_list)}, test triples:{len(test_triple_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ddabc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransE(torch.nn.Module):\n",
    "    def __init__(self, entity_num, relation_num, dim, margin):\n",
    "        super(TransE, self).__init__()\n",
    "        self.ent_emb = torch.nn.Embedding(num_embeddings=entity_num,\n",
    "                             embedding_dim=dim,\n",
    "                             device=0)\n",
    "        self.rel_emb = torch.nn.Embedding(num_embeddings=entity_num,\n",
    "                            embedding_dim=dim,\n",
    "                            device=0)\n",
    "        self.margin = margin\n",
    "        self.marginloss = torch.nn.MarginRankingLoss(self.margin, reduction='mean')\n",
    "        self.ent_normalization()\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.rel_normalization()\n",
    "    \n",
    "    def dist(self, h, r, t, norm=2):\n",
    "        if(norm == 2):\n",
    "            return (h + r - t).square().sum(axis=1).sqrt()\n",
    "        elif(norm == 1):\n",
    "            return (h + r - t).abs().sum(axis=1)\n",
    "    \n",
    "    def forward(self, current_list, corrupt_list):\n",
    "        h, r, t = torch.tensor(current_list).cuda().T.chunk(3)\n",
    "        h_ = self.ent_emb(h)\n",
    "        r_ = self.rel_emb(r)\n",
    "        t_ = self.ent_emb(t)\n",
    "        hc, rc, tc= torch.tensor(corrupt_list).cuda().T.chunk(3)\n",
    "        hc_ = self.ent_emb(hc)\n",
    "        rc_ = self.rel_emb(rc)\n",
    "        tc_ = self.ent_emb(tc)\n",
    "        return self.marginloss(self.dist(h_, r_, t_, 2), self.dist(hc_, rc_, tc_, 2), target=torch.tensor([-1]).cuda())\n",
    "    \n",
    "    def test_avg_rank(self, triple_list):\n",
    "        test_ent_ind = torch.tensor(list(range(len(entity_dict)))).view(-1,1).cuda()\n",
    "        ans = []\n",
    "        for triple in tqdm(triple_list):\n",
    "            h, t, r = triple\n",
    "            test_ent = self.ent_emb(torch.tensor(h).cuda())\n",
    "            test_rel = self.rel_emb(torch.tensor(t).cuda())\n",
    "            dist = np.array((test_ent + test_rel - self.ent_emb.weight.data).square().sum(dim=1).detach().cpu())\n",
    "            ans.append(dist.argsort().argsort()[r])\n",
    "        return np.mean(ans)\n",
    "    \n",
    "    def ent_normalization(self):\n",
    "        norm = self.ent_emb.weight.detach()\n",
    "        self.ent_emb.weight.data.copy_(norm / norm.square().sum(dim=1).sqrt().view(-1, 1))\n",
    "        \n",
    "    def rel_normalization(self):\n",
    "        norm = self.rel_emb.weight.detach()\n",
    "        self.rel_emb.weight.data.copy_(norm / norm.square().sum(dim=1).sqrt().view(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b958a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransE(len(entity_dict), len(relation_dict), 30, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c1f8e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "triple_sr_o_dict = {}\n",
    "for triple in train_triple_list:\n",
    "    if tuple(triple[:2]) in triple_sr_o_dict:\n",
    "        triple_sr_o_dict[tuple(triple[:2])].append(triple[2])\n",
    "    else:\n",
    "        triple_sr_o_dict[tuple(triple[:2])] = [triple[2]]\n",
    "triple_s_ro_dict = {}\n",
    "for triple in train_triple_list:\n",
    "    if tuple(triple[1:]) in triple_s_ro_dict:\n",
    "        triple_s_ro_dict[tuple(triple[1:])].append(triple[0])\n",
    "    else:\n",
    "        triple_s_ro_dict[tuple(triple[1:])] = [triple[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "201ae72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [55:26<00:00,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1000, total_loss:0.004080391023308039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optim = torch.optim.Adagrad(params=model.parameters(), lr=0.1)\n",
    "batch_size=400\n",
    "best_mean_rank = 9999\n",
    "for epoch in tqdm(range(1000)):\n",
    "    indices = list(range(len(train_triple_list)))\n",
    "    random.shuffle(indices)\n",
    "    total_loss = 0\n",
    "    model.ent_normalization()\n",
    "    for i in range(0, len(indices), batch_size):\n",
    "        ind = indices[i:i+batch_size]\n",
    "        current_list = []\n",
    "        corrupt_list = []\n",
    "        for j in ind:\n",
    "            current_list.append(train_triple_list[j].copy())\n",
    "            flag = random.randint(0, 1)\n",
    "            corrupt = train_triple_list[j].copy()\n",
    "            if flag == 0:\n",
    "                corrupt[0] = random.randint(0, len(entity_dict) - 1)\n",
    "                while corrupt[0] in triple_s_ro_dict[tuple(corrupt[1:])]:\n",
    "                    corrupt[0] = random.randint(0, len(entity_dict) - 1)\n",
    "            else:\n",
    "                corrupt[2] = random.randint(0, len(entity_dict) - 1)\n",
    "                while corrupt[2] in triple_sr_o_dict[tuple(corrupt[:2])]:\n",
    "                    corrupt[2] = random.randint(0, len(entity_dict) - 1)\n",
    "            corrupt_list.append(corrupt.copy())\n",
    "        loss = model(current_list, corrupt_list)\n",
    "        with torch.no_grad():\n",
    "            total_loss += loss\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "#     val_mean_rank = model.test_avg_rank(valid_triple_list)\n",
    "#     if val_mean_rank < best_mean_rank:\n",
    "#         best_ent_emb = model.ent_emb.weight.data.clone().detach()\n",
    "#         best_rel_emb = model.rel_emb.weight.data.clone().detach()\n",
    "#         best_mean_rank = val_mean_rank\n",
    "#     print(f'epoch:{epoch+1}, total_loss:{loss}, average val rank:{val_mean_rank}, average test rank:{model.test_avg_rank(test_triple_list)},')\n",
    "#     if (epoch+1) % 20 ==0:\n",
    "print(f'epoch:{epoch+1}, total_loss:{total_loss}')\n",
    "# print(f'average test rank:{model.test_avg_rank(test_triple_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bbeb0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4054/4054 [00:52<00:00, 77.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1958.6211149481994"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test_avg_rank(test_triple_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "332e6235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.4122,  1.0000, 12.5320,  ...,  1.0000,  1.0000,  1.0000],\n",
       "       device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.rel_emb.weight.square().sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a481802",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.2650,  0.3409, -0.3161,  ...,  0.2802,  0.2604,  0.3919],\n",
       "        [ 0.1042,  0.1707, -0.1803,  ..., -0.0386, -0.0213, -0.0116],\n",
       "        [-0.2665,  0.6386,  0.0506,  ...,  0.5907,  0.7249, -0.3995],\n",
       "        ...,\n",
       "        [-0.0520,  0.1034,  0.0428,  ...,  0.0162, -0.1489,  0.0209],\n",
       "        [-0.2361,  0.1025, -0.0923,  ...,  0.0259, -0.0780, -0.0339],\n",
       "        [-0.1042,  0.3670,  0.1416,  ...,  0.0303,  0.0461, -0.1750]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.rel_emb.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a0a529af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1759, -0.0820,  0.0613,  ...,  0.1061,  0.0132,  0.4462],\n",
       "        [-0.1326, -0.1097, -0.0347,  ..., -0.2063, -0.1606, -0.0027],\n",
       "        [-0.0672, -0.0097,  0.0890,  ..., -0.0621,  0.0165,  0.1894],\n",
       "        ...,\n",
       "        [-0.0630, -0.3686, -0.1978,  ..., -0.0457,  0.1254, -0.2180],\n",
       "        [-0.1293,  0.1631,  0.1848,  ..., -0.0172,  0.0541, -0.1772],\n",
       "        [-0.0005,  0.2539,  0.0080,  ..., -0.0177, -0.0221, -0.1125]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.ent_emb.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0d7088d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_ent_emb, 'best_entity_embedding_TransE_rank_' + str(round(best_mean_rank, 2)))\n",
    "torch.save(best_ent_emb, 'best_relation_embedding_TransE_rank_' + str(round(best_mean_rank, 2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
